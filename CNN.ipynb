{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikilsaldanaha/Documents/Code/MLNotebooks/env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32).reshape((-1, 28 * 28)) / 255.\n",
    "X_test = X_test.astype(np.float32).reshape((-1, 28 * 28)) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_temp = y_test.copy()\n",
    "y_train_temp = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.zeros((y_test_temp.size, 10))\n",
    "y_test[np.arange(y_test_temp.size), y_test_temp] = 1\n",
    "\n",
    "y_train = np.zeros((y_train_temp.size, 10))\n",
    "y_train[np.arange(y_train_temp.size), y_train_temp] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_classes = 10\n",
    "dropout = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, n_classes), name='y')\n",
    "keep_prob = tf.placeholder(tf.float32, shape=(), name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(X, W, b, stride=1):\n",
    "    \"\"\"\n",
    "    Convolutional Layer\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: Tensor of shape (batch_size, height, width, n_input_channels)\n",
    "        Input Image\n",
    "    \n",
    "    W: Tensor of shape (filter_height, filter_width, n_input_channels, n_output_channels)\n",
    "        Filter\n",
    "    \n",
    "    b: Tensor of shape (n_output_channels,)\n",
    "        Bias\n",
    "    \n",
    "    stride: int\n",
    "        Stride\n",
    "    \"\"\"\n",
    "    conv_out = tf.nn.conv2d(X, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    conv_out = tf.nn.bias_add(conv_out, b)\n",
    "    relu = tf.nn.relu(conv_out)\n",
    "    return relu\n",
    "\n",
    "def maxpool_layer(X, k=2):\n",
    "    return tf.nn.max_pool(X, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "def conv_net(X, W, b):\n",
    "    X = tf.reshape(X, shape=(-1, 28, 28, 1))\n",
    "    \n",
    "    conv1 = conv_layer(X, W['W_CONV_1'], b['B_CONV_1'])\n",
    "    conv1 = maxpool_layer(conv1, k=2)\n",
    "    \n",
    "    conv2 = conv_layer(conv1, W['W_CONV_2'], b['B_CONV_2'])\n",
    "    conv2 = maxpool_layer(conv2, k=2)\n",
    "    \n",
    "    fc1 = tf.reshape(conv2, (-1, W['W_FC_1'].get_shape().as_list()[0]))\n",
    "    fc1 = tf.add(tf.matmul(fc1, W['W_FC_1']), b['B_FC_1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    out = tf.add(tf.matmul(fc1, W['OUT']), b['OUT'])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = {\n",
    "    # 5x5 CONV, 1 input, 32 outputs\n",
    "    'W_CONV_1': tf.Variable(tf.random_normal((5, 5, 1, 32))),\n",
    "    \n",
    "    # 5x5 CONV, 32 inputs, 64 outputs\n",
    "    'W_CONV_2': tf.Variable(tf.random_normal((5, 5, 32, 64))),\n",
    "    \n",
    "    # FC, 7*7*64 inputs, 1024 outputs\n",
    "    'W_FC_1': tf.Variable(tf.random_normal((7*7*64, 1024))),\n",
    "    \n",
    "    # 1024 inputs, 10 outputs\n",
    "    'OUT': tf.Variable(tf.random_normal((1024, n_classes)))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'B_CONV_1': tf.Variable(tf.random_normal((32,))),\n",
    "    'B_CONV_2': tf.Variable(tf.random_normal((64,))),\n",
    "    'B_FC_1': tf.Variable(tf.random_normal((1024,))),\n",
    "    'OUT': tf.Variable(tf.random_normal((n_classes,))),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = conv_net(X, weight, bias)\n",
    "predictions = tf.nn.softmax(logits)\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, labels=y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimize_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.equal(tf.argmax(predictions, axis=1), tf.argmax(y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    \n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch = X[batch_idx]\n",
    "        y_batch = y[batch_idx]\n",
    "        \n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss = 90435.6953125, accuracy = 0.13178294897079468\n",
      "step 10: loss = 55376.44921875, accuracy = 0.1860465109348297\n",
      "step 20: loss = 37931.41015625, accuracy = 0.2945736348628998\n",
      "step 30: loss = 24829.33203125, accuracy = 0.40310078859329224\n",
      "step 40: loss = 21526.392578125, accuracy = 0.5116279125213623\n",
      "step 50: loss = 12973.8681640625, accuracy = 0.5813953280448914\n",
      "step 60: loss = 9727.794921875, accuracy = 0.643410861492157\n",
      "step 70: loss = 9018.072265625, accuracy = 0.6589147448539734\n",
      "step 80: loss = 10553.1005859375, accuracy = 0.643410861492157\n",
      "step 90: loss = 5876.2490234375, accuracy = 0.7286821603775024\n",
      "step 100: loss = 9237.666015625, accuracy = 0.78125\n",
      "step 110: loss = 5631.43359375, accuracy = 0.7890625\n",
      "step 120: loss = 3646.650390625, accuracy = 0.8046875\n",
      "step 130: loss = 4209.49169921875, accuracy = 0.8046875\n",
      "step 140: loss = 2292.027587890625, accuracy = 0.8671875\n",
      "step 150: loss = 3959.86328125, accuracy = 0.8359375\n",
      "step 160: loss = 4414.4541015625, accuracy = 0.78125\n",
      "step 170: loss = 3203.30859375, accuracy = 0.8671875\n",
      "step 180: loss = 4824.677734375, accuracy = 0.8046875\n",
      "step 190: loss = 2973.11083984375, accuracy = 0.8515625\n",
      "step 200: loss = 2860.07763671875, accuracy = 0.8359375\n",
      "step 210: loss = 2805.4306640625, accuracy = 0.84375\n",
      "step 220: loss = 3035.235107421875, accuracy = 0.8046875\n",
      "step 230: loss = 4022.110595703125, accuracy = 0.7578125\n",
      "step 240: loss = 1036.2718505859375, accuracy = 0.90625\n",
      "step 250: loss = 1679.684814453125, accuracy = 0.8984375\n",
      "step 260: loss = 2389.873046875, accuracy = 0.8515625\n",
      "step 270: loss = 3622.37109375, accuracy = 0.84375\n",
      "step 280: loss = 3308.704345703125, accuracy = 0.8515625\n",
      "step 290: loss = 2152.560302734375, accuracy = 0.890625\n",
      "step 300: loss = 1976.028076171875, accuracy = 0.890625\n",
      "step 310: loss = 2533.376953125, accuracy = 0.8984375\n",
      "step 320: loss = 2468.93896484375, accuracy = 0.84375\n",
      "step 330: loss = 1409.451171875, accuracy = 0.90625\n",
      "step 340: loss = 2783.57861328125, accuracy = 0.859375\n",
      "step 350: loss = 1540.185302734375, accuracy = 0.890625\n",
      "step 360: loss = 994.2846069335938, accuracy = 0.921875\n",
      "step 370: loss = 1824.463623046875, accuracy = 0.8984375\n",
      "step 380: loss = 1288.632568359375, accuracy = 0.921875\n",
      "step 390: loss = 1716.00146484375, accuracy = 0.8984375\n",
      "step 400: loss = 1515.85791015625, accuracy = 0.8984375\n",
      "step 410: loss = 1046.101806640625, accuracy = 0.8984375\n",
      "step 420: loss = 907.0874633789062, accuracy = 0.921875\n",
      "step 430: loss = 2092.953857421875, accuracy = 0.875\n",
      "step 440: loss = 976.812255859375, accuracy = 0.90625\n",
      "step 450: loss = 1625.0740966796875, accuracy = 0.9140625\n",
      "step 460: loss = 3192.026611328125, accuracy = 0.8515625\n",
      "Testing Accuracy: 0.9523000121116638\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step, (batch_X, batch_y) in enumerate(get_batch(X_train, y_train, batch_size)):\n",
    "        sess.run(optimize_op, feed_dict={X: batch_X,\n",
    "                                         y: batch_y,\n",
    "                                         keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_X,\n",
    "                                                                 y: batch_y,\n",
    "                                                                 keep_prob: dropout})\n",
    "            print(\"step {step}: loss = {loss}, accuracy = {acc}\".format(step=step,\n",
    "                                                                        loss=loss,\n",
    "                                                                        acc=acc))\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test,\n",
    "                                             y: y_test,\n",
    "                                             keep_prob: 1.0})\n",
    "    print(\"Testing Accuracy: {}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
